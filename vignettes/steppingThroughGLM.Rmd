---
title: "Stepping through a GLMM"
author: "Ben Dilday"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

I'm working on adding a multinomial model to `lme4`. In order to figure out where the best places to change existing code and the best places to reuse existing code are, I've stepped through `glmer` bit by bit. 

## tracing the code

As part of my work with `lme4`, I;ve added some reproducible simulated data. To use th esame data as I'm working woth here you caninstall from github,

``` {r, eval=FALSE}
devtools::install_github('bdilday/lme4', ref='dev-multinomial')
library(lme4)
```

``` {r, message=FALSE, echo=FALSE}
library(lme4)
```

generate some simulated data. 

``` {r}
df1 <- simulate_data(n_matchup = 10)
table(df1$outcome)
```

Since I'm focusing on multinomial models, my simulated data has more than 2 classes, but here I force there to be only two.

``` {r}
cc <- which(df1$outcome > 1)
df1[cc,]$outcome <- 1
table(df1$outcome)
```

## step through binomial glmer

Using debug, I step through `glmer`,

``` {r, eval=FALSE}
debug(glmer)
mod1 <- glmer(outcome ~ (1|fB) + (1|fP), data=df1, nAGQ = 0, family = binomial, control=lme4::glmerControl(optimizer = "nloptwrap"))
```

There are a bunch of checks, and eventually we come to,

``` {r, eval=FALSE}
devfun <- do.call(mkGlmerDevfun, c(glmod, list(verbose = verbose,
                                               control = control,
                                               nAGQ = nAGQinit)))
```

Before stepping further I add a debug command for `mkGlmerDevFun`. 

``` {r, eval=FALSE}
debug(mkGlmerDevFun)
```

Stepping through `mkGlmerDevFun` we come to,

``` {r, eval=FALSE}
mkRespMod(fr, family=family)
```

Debug that one...

``` {r, eval=FALSE}
debug(mkRespMod)
```

We come to,

``` {r, eval=FALSE}
ans <- do.call(new, c(list(Class="glmResp", family=family),
                      ll[setdiff(names(ll), c("m", "nobs", "mustart"))]))
```

Now here's where it gets interesting

## down the rabbit hole

The call above (`new`) instantiates an `R` `S4` object of class `glmresp`. The code for that (from `AllClass.R` in `lme4`) looks like,

``` {r, eval=FALSE}
glmResp <-
  setRefClass("glmResp", contains = "lmResp",
              fields = list(eta = "numeric", family = "family", n = "numeric"),
              methods=
                list(initialize = function(...) {
                  callSuper(...)
                  ll <- list(...)
                  if (is.null(ll$family)) stop("family must be specified")
                  family <<- ll$family
                  n <<- if (!is.null(ll$n)) as.numeric(ll$n) else rep.int(1,length(y))
                  eta <<- if (!is.null(ll$eta)) as.numeric(ll$eta) else numeric(length(y))
                },
```

and etc...

The `contains="lmResp"` line means that the `glmResp` class inherits from `lmResp`; if you look at the definition of `lmResp` you see that one of the fields is an external pointer (`externalptr`), `Ptr`.

``` {r, eval=FALSE}
lmResp <-
  setRefClass("lmResp",
              fields =
                list(Ptr     = "externalptr",
                     mu      = "numeric",
                     offset  = "numeric",
                     sqrtXwt = "numeric",
                     sqrtrwt = "numeric",
                     weights = "numeric",
                     wtres   = "numeric",
                     y       = "numeric"),
              methods =
```

For the `lmResp` class, `Ptr` is explictly instantiated, but for the `glmResp` class, the instantiation of `Ptr` happens indeirectly through a call to `ptr()`. The code looks like,

``` {r, eval=FALSE}
ptr       = function() {
  'returns the external pointer, regenerating if necessary'
  if (length(y)) {
    if (.Call(isNullExtPtr, Ptr)) {
      Ptr <<- .Call(glm_Create, family, y, weights, offset, mu, sqrtXwt,
                    sqrtrwt, wtres, eta, n)
      .Call(glm_updateMu, Ptr, eta - offset)
    }
  }
  Ptr
}
```

The `.Call(glm_Create...)` instantiates a `glmResp` object implemented in `C++`. The code looks like,

``` {r, eval=FALSE}
glmResp::glmResp(List fam, SEXP y, SEXP weights, SEXP offset,
		     SEXP mu, SEXP sqrtXwt, SEXP sqrtrwt, SEXP wtres, SEXP eta, SEXP n)
	: lmResp(y, weights, offset, mu, sqrtXwt, sqrtrwt, wtres),
	  d_fam(fam),
	  d_eta(as<MVec>(eta)),
	  d_n(as<MVec>(n)) {
	  }
```

As with the `R` definition of a `glmResp` object, this derives from the `lmResp` class (but implemented in `C++`); this `C++` `glmResp` object is essentially a mirror of the `glmResp` object implemented in `R`.

To go back to the instantiation of the `Ptr`, thorugh the `ptr()` function, in the `R` version of `glmResp`, the next step is

``` {r, eval=FALSE}
.Call(glm_updateMu, Ptr, eta - offset)
```

The body of `glm_updateMu` looks like,

``` {r, eval=FALSE}
SEXP glm_updateMu(SEXP ptr_, SEXP gamma) {
  BEGIN_RCPP;
  return ::Rf_ScalarReal(XPtr<glmResp>(ptr_)->updateMu(as<MVec>(gamma)));
  END_RCPP;
}
```

So the `R` code (remember we're still inside of `do.call(new, c(list(Class="glmResp"...)))`) calls a `C++` function, passing it a pointer to an `C++` object, and a numeric vector. The pointer is explicitly cast as a pointer to a `glmResp` type (the `C++` version, not the `R` version), and the method `updateMu`, of the `C++` object, is called. The body of the `updateMu` method looks like,

``` {r, eval=FALSE}
double glmResp::updateMu(const VectorXd& gamma) {
  d_eta = d_offset + gamma;
  d_mu  = d_fam.linkInv(d_eta);
  return updateWrss();
}
```

The `updateMu` method not only updates `mu` based on `gamma`, the linear predictor, but also calls `updateWrss`, which we'll come back to.

Before coming to that, note the call `d_mu  = d_fam.linkInv(d_eta);`. This calls, 

``` {r, eval=FALSE}
const ArrayXd glmLink::linkInv(const ArrayXd& eta) const {
  return as<ArrayXd>(::Rf_eval(
    ::Rf_lang2(as<SEXP>(d_linkInv),
               as<SEXP>(Rcpp::NumericVector(eta.data(),
                                            eta.data() + eta.size()))
    ), d_rho));
}
```

This is a `C++` function **that calls back to the `R` definition of the `linkInv` function, `d_linkInv`**. For this particular model, and particular family and link function, is,

``` {r}
(binomial())$linkinv 
```

`C_logit_linkinv` applies the inverse logit, and is defined in the `C` source code of the `stats` module of base `R`. 

## review

Phew. Ok let's review that.

* We instantiate a `glmResp` object in `R`

* As part of this process, we instantiate a parallel `glmResp` object in `C++`

* Instantiating this pointer calls an `updateMu` method on the `C++` object

* as part of it's execution, the `updateMu` method calls the `linkInv` function of the `C++` object

* this `C++` object calls the `R` version of `linkInv`

* the `R` version of `linkInv` calls a `C` version of the inverse link

This seems like a lot of indirection. I assume the reason for that is to have flexibility in specifying family and link function of a general `GLMM`; but it seems to add a new, multinomial, model, some of these middle-man steps could be taken out. For example, don't bother creating a `glmResp` object in `C++`, just crate an `R` one; don't use a `C++` function to call an `R` function, which then calls a `C` function, just execute the inverse link in `C++` directly;

## optimization

When it come to the optimization loop, the model is optimized over $\theta$. The optimization over the fixed and random effects is performed with `PIRLS` for each increment of $\theta$. The steps for `PIRLS` are,

* call `devfun`. For a `binomial` model this looks like,

```
function(theta) {
  resp$updateMu(lp0)
	pp$setTheta(theta)
	p <- pwrssUpdate(pp, resp, tol=tolPwrss, GQmat=GHrule(0L),
                   compDev=compDev, maxit=maxit, verbose=verbose)
  resp$updateWts()
  p
}
<environment: 0x[something]>
```

This executes for each new value of theta during the optimization. I think (but not 100% certain) that `lp0` is fixed, so the line `resp$updateMu(lp0)` initializes $\mu$ to the same inigtial value at each itearion. The statement `pp$setTheta(theta)` is straight forward and just causes theta to be set. 

The `compDev` argument controls whether the code is excuted in `C++` or in `R`. If it is `TRUE` then the `pwrssUpdate` code essentially returns,

```
return(.Call(glmerLaplace, pp$ptr(), resp$ptr(),
                         nAGQ, tol, as.integer(maxit),
                         verbose))
```

`glmerLaplace` is `C++` function that looks like,

```
SEXP glmerLaplace(SEXP pp_, SEXP rp_, SEXP nAGQ_, SEXP tol_, SEXP maxit_, SEXP verbose_) {
        BEGIN_RCPP;
        XPtr<glmResp>  rp(rp_);
        XPtr<merPredD> pp(pp_);

	pwrssUpdate(rp, pp, ::Rf_asInteger(nAGQ_), ::Rf_asReal(tol_), 
		    ::Rf_asInteger(maxit_), ::Rf_asInteger(verbose_));

        return ::Rf_ScalarReal(rp->Laplace(pp->ldL2(), pp->ldRX2(), pp->sqrL(1.)));
        END_RCPP;
    }
```

`pwrssUpdate` is pretty complex and looks like,

```
static void pwrssUpdate(glmResp *rp, merPredD *pp, bool uOnly,
			    double tol, int maxit, int verbose) {
	double oldpdev=std::numeric_limits<double>::max();
	double pdev;
	int maxstephalfit = 10;
	bool   cvgd = false, verb = verbose > 2, moreverb = verbose > 10;
	int debug=0;

	pdev = oldpdev; // define so debugging statements work on first step
	for (int i = 0; i < maxit; i++) {
	    if (verb) {
		Rcpp::Rcout << "*** pwrssUpdate step " << i << std::endl;
		if (debug) {
		    Rcpp::Rcout << "\nmin delu at iteration " << i << ": " << pp->delu().minCoeff() << std::endl;
		    Rcpp::Rcout << "\nmax delu at iteration " << i << ": " << pp->delu().maxCoeff() << std::endl;
		    Rcpp::Rcout << "\nresDev before dels, iter:  " << i << ",  " << rp->resDev() << std::endl;
		// FIXME: would like to print this in row, not column, format
		// 
		    Rcpp::Rcout << "before update:" << "pdev = " << pdev << std::endl; // if (verb) 
		}
	    }
	    Vec   olddelu(pp->delu()), olddelb(pp->delb());
	    pdev = internal_glmerWrkIter(pp, rp, uOnly);
	    if (verb) {
		Rcpp::Rcout << "pdev=" << pdev << 
		    "; delu_min: " << pp->delu().minCoeff() <<
		    "; delu_max: " << pp->delu().maxCoeff() <<
		    "; delb_min: " << pp->delb().minCoeff() <<
		    "; delb_max: " << pp->delb().maxCoeff() <<
		    std::endl; // if (verb) 
	    }
	    if (std::abs((oldpdev - pdev) / pdev) < tol) {cvgd = true; break;}

	    // if (pdev != pdev) Rcpp::Rcout << "nan detected" << std::endl;
	    // if (isnan(pdev)) Rcpp::Rcout << "nan detected" << std::endl;

	    // trying to detect nan; may be hard to do it completely portably,
	    // and hard to detect in advance (i.e. what conditions lead to
	    // nan from internal_glmerWrkIter ... ?)
	    // http://stackoverflow.com/questions/570669/checking-if-a-double-or-float-is-nan-in-c
	    // check use of isnan() in base R code, or other Rcpp code??
#define isNAN(a)  (a!=a)
	    if (isNAN(pdev) || (pdev > oldpdev)) { 
		// PWRSS step led to _larger_ deviation, or nan; try step halving
		if (verb) Rcpp::Rcout << 
			      "\npwrssUpdate: Entering step halving loop" 
				      << std::endl;
		for (int k = 0; k < maxstephalfit && 
			 (isNAN(pdev) || (pdev > oldpdev)); k++) {
		    pp->setDelu((olddelu + pp->delu())/2.);
		    if (!uOnly) pp->setDelb((olddelb + pp->delb())/2.);
		    rp->updateMu(pp->linPred(1.));
		    pdev = rp->resDev() + pp->sqrL(1.);
		    if (moreverb) {
			Rcpp::Rcout << "step-halving iteration " <<
			    k << ":  pdev=" << pdev << 
			    "; delu_min: " << pp->delu().minCoeff() <<
			    "; delu_max: " << pp->delu().maxCoeff() <<
			    "; delb_min: " << pp->delb().minCoeff() <<
			    "; delb_max: " << pp->delb().maxCoeff() <<
			    std::endl; 
		    } // if (moreverb) 
		}
		if (isNAN(pdev) || ((pdev - oldpdev) > tol) )
		    // FIXME: fill in max halfsetp iters in error statement
		    throw runtime_error("(maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate");
	    } // step-halving
	    oldpdev = pdev;
	} // pwrss loop
	if (!cvgd)
	    // FIXME: fill in max iters in error statement
	    throw runtime_error("pwrssUpdate did not converge in (maxit) iterations");
    }
```